import streamlit as st
import pandas as pd
from io import StringIO
import re
import spacy
import io

st.set_page_config(
    page_title="–¢–µ—Å—Ç –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤"
)

st.title("–¢–µ—Å—Ç –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤")

st.info("–ó–¥–µ—Å—å –º–æ–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤, –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –Ω–∞ Pathway", 
        icon="üí°")

with st.expander("–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ"):
            st.write("–°–∫—Ä–∏–ø—Ç —É–º–µ–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å —Ç–∏–ø—ã –≤–æ–ø—Ä–æ—Å–æ–≤: "
            "\n * Scale -- —à–∫–∞–ª–∞. –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ–ø-2"
            "\n * Choice -- –∑–∞–∫p—ã—Ç—ã–π –≤–æ–ø—Ä–æ—Å —Å –æ–¥–Ω–∏–º –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –≤–∞—Ä–∏–∞–Ω—Ç–∞–º–∏ –æ—Ç–≤–µ—Ç–∞. –û—Ç–≤–µ—Ç—ã –≤—ã–≤–æ–¥—è—Ç—Å—è –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã"
            "\n * Question -- –æ—Ç–∫—Ä—ã—Ç—ã–π –≤–æ–ø—Ä–æ—Å. –í—ã–≤–æ–¥–∏—Ç—Å—è —Ç–æ–ø-20 –Ω–∞–∏–±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö —Å–ª–æ–≤" 
            "\n * Preference -- –≤—ã–±–æ—Ä –º–µ–¥–∏–∞. –í–∞—Ä–∏–∞–Ω—Ç—ã –≤—ã–≤–æ–¥—è—Ç—Å—è –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã"
            "\n\n –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ñ–æ—Ä–º–∏—Ä—É—é—Ç—Å—è –æ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∞–Ω–∫–µ—Ç. "
            "–ó–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–º–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è –∞–Ω–∫–µ—Ç—ã, –≥–¥–µ –µ—Å—Ç—å –æ—Ç–≤–µ—Ç –Ω–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å, –∫–æ—Ç–æ—Ä—ã–π –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Ç–∫—Ä—ã—Ç—ã–º")


uploaded_files = st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã Excel", type='xlsx', accept_multiple_files=True)

if st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å"):
    k = 0
    data = pd.DataFrame()

    for uploaded_file in uploaded_files:
        k+=1
        temp_data = pd.read_excel(uploaded_file, engine="openpyxl")
        temp_data["0_concept_n"] = k
        if k == 1:
            columns = temp_data.columns
        else:
            temp_data.columns = columns
        data = pd.concat([data, temp_data])

    data = data.drop(columns=[col for col in data.columns if "Other (text)" in col])
    data = data.drop(columns=[col for col in data.columns if "other answers" in col])
    data = data.drop(columns = ["Completion time, ms", "Answer Date"])
    cols = data.columns

    open_qst = cols[cols.str.contains("Question")]
    choice = cols[cols.str.contains("Choice")]
    
    choice_clean = []
    for i in choice:
        index = i.rfind(':')
        if index != -1:
            clean = i[:index]
            if clean not in choice_clean:
                choice_clean.append(clean)
        else:
            choice_clean.append(i)


    scale = cols[cols.str.contains("Scale")]
    preference = cols[cols.str.contains("Preference")]

    for i in cols:
         if "Question" not in i and "0_concept_n" not in i and "Other (text)" not in i:
              last_q = i

    data = data.loc[data[last_q].notna()]
    data.reset_index(drop=True, inplace = True)

    results = pd.DataFrame()

# –≤–æ–ø—Ä–æ—Å—ã —Å –≤—ã–±–æ—Ä–æ–º –æ—Ç–≤–µ—Ç–∞
    for choice in choice_clean:
         # try:
             temp_data = data.filter(like=choice)

             if temp_data.shape[1] == 1:
                 temp = pd.crosstab(data[choice], data["0_concept_n"], margins = True)
                 temp.iloc[:-1,:] = temp.iloc[:-1,:]/temp.iloc[-1,:]
                 temp.drop(index = "All", inplace = True)
                 temp = temp.rename(columns={"All": "–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º"})                
                 temp.index.name = "–û—Ç–≤–µ—Ç—ã"
                 temp["–í–æ–ø—Ä–æ—Å"] = choice
                 temp = temp.set_index("–í–æ–ø—Ä–æ—Å", append=True)
                 temp = temp.swaplevel()
                 temp["‚Ññ"] = int(choice.split(".")[0])
                 temp.sort_values(by="–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º", ascending=False, inplace = True)
                 results = pd.concat([results, temp])
                 
             
             else:
                clean_ans = []
                for col in temp_data.columns:
                    index = col.rfind(':')
                    clean = col[index+2:]
                    clean_ans.append(clean)
                temp_data.columns = clean_ans
                temp_data.dropna(axis = 0, inplace = True)
                temp_data["0_concept_n"] = data.loc[temp_data.index, "0_concept_n"]
                temp = temp_data.groupby("0_concept_n").sum().T
                temp["–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º"] = temp.sum(axis = 1)
                bases = list(temp_data.groupby("0_concept_n").count()[clean_ans[0]])
                bases.append(sum(bases))
                temp.index.name = "–û—Ç–≤–µ—Ç—ã"
                temp["–í–æ–ø—Ä–æ—Å"] = choice
                temp = temp.set_index("–í–æ–ø—Ä–æ—Å", append=True)
                temp = temp.swaplevel()
                temp = temp / bases
                temp["‚Ññ"] = int(choice.split(".")[0])
                temp.sort_values(by="–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º", ascending=False, inplace = True)
                results = pd.concat([results, temp])
             
         # except:
             # st.error(f"–í–æ–∑–Ω–∏–∫–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≤–æ–ø—Ä–æ—Å–∞ **{choice}**")
            
# –≤—ã–±–æ—Ä –º–µ–¥–∏–∞
    for i in preference:
        temp = pd.crosstab(data[i], data["0_concept_n"], margins = True)
        temp.iloc[:-1,:] = temp.iloc[:-1,:]/temp.iloc[-1,:]
        temp.drop(index = "All", inplace = True)
        temp = temp.rename(columns={"All": "–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º"})                
        temp.index.name = "–û—Ç–≤–µ—Ç—ã"
        temp["–í–æ–ø—Ä–æ—Å"] = i
        temp = temp.set_index("–í–æ–ø—Ä–æ—Å", append=True)
        temp = temp.swaplevel()
        temp["‚Ññ"] = int(i.split(".")[0])
        temp.sort_values(by="–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º", ascending=False, inplace = True)
        results = pd.concat([results, temp])

# —à–∫–∞–ª—å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    nums = []
    temp_res = pd.DataFrame()
    for i in scale:
        try:
            temp_data = data.loc[data[i].notna(), [i, "0_concept_n"]]
            temp_data[i].astype('int64')
            if min(temp_data[i]) < 0:
                temp_data[i] = temp_data[i].replace([-2, -1, 0], 0)
                temp_data[i] = temp_data[i].replace([1, 2], 1)
            else:
                temp_data[i] = temp_data[i].replace([1, 2, 3], 0)
                temp_data[i] = temp_data[i].replace([4, 5], 1)
            temp = temp_data.groupby("0_concept_n").sum().T
            temp["–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º"] = temp.sum(axis = 1)
            bases = list(temp_data.groupby("0_concept_n").count()[i])
            bases.append(sum(bases))
            temp.index.name = "–í–æ–ø—Ä–æ—Å"
            temp["–û—Ç–≤–µ—Ç—ã"] = "–¢–æ–ø-2 (–æ—Ü–µ–Ω–∫–∏ 4-5)"
            temp = temp.set_index("–û—Ç–≤–µ—Ç—ã", append=True)
            temp = temp / bases
            num = i.split(".")[0]
            nums.append(int(num))
            temp_res = pd.concat([temp_res, temp], axis = 0)

        except:
             st.error(f"–í–æ–∑–Ω–∏–∫–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≤–æ–ø—Ä–æ—Å–∞ **{i}**")

    temp_res["‚Ññ"] = nums
    results = pd.concat([results, temp_res], axis = 0)
    results.sort_values(by=["‚Ññ", "–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º"], ascending=[True, False], inplace = True)
        
    # –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
    temp = pd.DataFrame(columns = results.columns, index = [open_qst])
    nlp = spacy.load('ru_core_news_lg')
    for i in open_qst:
        try:
            texts = data.loc[data[i].notna(), i]
            doc = nlp(" ".join(texts.astype(str)).lower())
            keywords_freq = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]
            keywords = {}
            for key in keywords_freq:
                if not keywords.get(key, False):
                    keywords[key] = 1
                else:
                    keywords[key] += 1
            sorted_keys = dict(sorted(keywords.items(), key=lambda item: item[1], reverse = True))
            frq_fin = pd.DataFrame(data = sorted_keys, index = ["–ß–∞—Å—Ç–æ—Ç–∞"]).T
            frq_fin["–°–ª–æ–≤–æ"] = frq_fin.index
            frq_fin.index = [i for i in range(len(frq_fin))]
            temp["–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º"][i] = (", ").join(frq_fin[:20]["–°–ª–æ–≤–æ"])
            n_con = list(data["0_concept_n"].unique())
            for j in n_con:
                data_temp = data.loc[data["0_concept_n"] == j]
                texts = data_temp.loc[data_temp[i].notna(), i]
                doc = nlp(" ".join(texts.astype(str)).lower())
                keywords_freq = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]
                keywords = {}
                for key in keywords_freq:
                    if not keywords.get(key, False):
                        keywords[key] = 1
                    else:
                        keywords[key] += 1
                sorted_keys = dict(sorted(keywords.items(), key=lambda item: item[1], reverse = True))
                frq_fin = pd.DataFrame(data = sorted_keys, index = ["–ß–∞—Å—Ç–æ—Ç–∞"]).T
                frq_fin["–°–ª–æ–≤–æ"] = frq_fin.index
                frq_fin.index = [k for k in range(len(frq_fin))]
                temp[j][i] = (", ").join(frq_fin[:20]["–°–ª–æ–≤–æ"])
        except:
             st.error(f"–í–æ–∑–Ω–∏–∫–ª–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –≤–æ–ø—Ä–æ—Å–∞ **{i}**")
    
    nums = []
    for i in open_qst:
         num = i.split(".")[0]
         nums.append(int(num))
    temp["‚Ññ"] = nums
    temp.index.name = "–í–æ–ø—Ä–æ—Å"
    temp["–û—Ç–≤–µ—Ç—ã"] = "–¢–æ–ø-20 —Å–ª–æ–≤"
    temp = temp.set_index("–û—Ç–≤–µ—Ç—ã", append=True)

    results = pd.concat([results, temp], axis = 0)
    results.sort_values(by=["‚Ññ", "–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º"], ascending=[True, False], inplace = True)
    results.drop(columns=["‚Ññ"], inplace=True)
    
    bases = list(data.groupby("0_concept_n").count()[last_q])
    bases.append(sum(bases))
    bases_pd = pd.DataFrame(index = results.columns, columns = ["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤"])
    bases_pd["–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—Ç–æ–≤"] = bases
    bases_pd = bases_pd.T
    bases_pd.index.name = "–í–æ–ø—Ä–æ—Å"
    bases_pd["–û—Ç–≤–µ—Ç—ã"] = ""
    bases_pd = bases_pd.set_index("–û—Ç–≤–µ—Ç—ã", append=True)

    results = pd.concat([results, bases_pd], axis = 0)

    col = results.pop('–°—Ä–µ–¥–Ω–µ–µ –ø–æ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º')
    results.insert(0, col.name, col)

    buffer = io.BytesIO()
    with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
    # Write each dataframe to a different worksheet.
        results.to_excel(writer, merge_cells = True)
        writer.close()

    st.download_button(
        label="–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
        data=buffer,
        file_name="test_results.xlsx",
        mime="application/vnd.ms-excel"
    )
